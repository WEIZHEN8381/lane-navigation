{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OrScureymFU"
   },
   "source": [
    "# End-to-End Lane Navigation \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rihBIMTlM7rm"
   },
   "outputs": [],
   "source": [
    "# Mount my Google Drive.  It will ask for an authenticate code\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "model_output_dir = '/content/gdrive/My Drive/training_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7g38ulzZCAbR"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFZEdyZPtdMG"
   },
   "source": [
    "## Imports Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-w-982XpIjA"
   },
   "outputs": [],
   "source": [
    "# uninstall tensorflow 2.6.0 and install tensorflow 1.15.2\n",
    "!pip uninstall tensorflow\n",
    "!pip install tensorflow==1.15.2\n",
    "!pip install tensorflow_gpu==1.15.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-BJrGUh00Cp"
   },
   "outputs": [],
   "source": [
    "\n",
    "# python standard libraries\n",
    "import os\n",
    "import random\n",
    "import fnmatch\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "# data processing\n",
    "import numpy as np\n",
    "np.set_printoptions(formatter={'float_kind':lambda x: \"%.4f\" % x})\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 300)\n",
    "pd.set_option('display.float_format', '{:,.4f}'.format)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential  # V2 is tensorflow.keras.xxxx, V1 is keras.xxx\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "print( f'tf.__version__: {tf.__version__}' )\n",
    "print( f'keras.__version__: {keras.__version__}' )\n",
    "\n",
    "# sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# imaging\n",
    "import cv2\n",
    "from imgaug import augmenters as img_aug\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At4UECHhz9Pp"
   },
   "source": [
    "## Load Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q29fijIfVZYv"
   },
   "outputs": [],
   "source": [
    "# import images\n",
    "!cd /content\n",
    "\n",
    "!ls\n",
    "data_dir = '/content/gdrive/My Drive/trainingdata'\n",
    "file_list = os.listdir(data_dir)\n",
    "image_paths = []\n",
    "steering_angles = []\n",
    "pattern = \"*.png\"\n",
    "for filename in file_list:\n",
    "    if fnmatch.fnmatch(filename, pattern):\n",
    "        image_paths.append(os.path.join(data_dir,filename))\n",
    "        angle = int(filename[-7:-4])  # 092 part of video01_143_092.png is the angle. 90 is go straight\n",
    "        steering_angles.append(angle)\n",
    "\n",
    "image_index = 20\n",
    "plt.imshow(Image.open(image_paths[image_index]))\n",
    "print(\"image_path: %s\" % image_paths[image_index] )\n",
    "print(\"steering_Angle: %d\" % steering_angles[image_index] )\n",
    "df = pd.DataFrame()\n",
    "df['ImagePath'] = image_paths\n",
    "df['Angle'] = steering_angles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhsGlMrwVdE2"
   },
   "outputs": [],
   "source": [
    "# Look at the distribution of steering angle\n",
    "num_of_bins = 25\n",
    "samples_per_bin = 400\n",
    "hist, bins = np.histogram(df['Angle'], num_of_bins)\n",
    "\n",
    "fig, axes = plt.subplots(1,1, figsize=(12,4))\n",
    "axes.hist(df['Angle'], bins=num_of_bins, width=1, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xPqHnXq1gWRC"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split( image_paths, steering_angles, test_size=0.2)\n",
    "print(\"Training data: %d\\nValidation data: %d\" % (len(X_train), len(X_valid)))\n",
    "\n",
    "# plot the distributions of train and valid, make sure they are consistent\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,4))\n",
    "axes[0].hist(y_train, bins=num_of_bins, width=1, color='blue')\n",
    "axes[0].set_title('Training Data')\n",
    "axes[1].hist(y_valid, bins=num_of_bins, width=1, color='red')\n",
    "axes[1].set_title('Validation Data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaZEfJxdi796"
   },
   "source": [
    "##Image Augumentation\n",
    "Since we only have a few hundred images, to train a deep network, we need a lot more images.   Instead of running our car, let's try to augment our data. There are a couple of ways to do that.\n",
    "\n",
    "1. Zoom: crop out a smaller image from the center\n",
    "1. Pan: crop out a smaller image from left or right side\n",
    "1. adjust brightness of the image\n",
    "1. flip the image horizontally, i.e do a left to right flip, and change the steering angle coorespondingly\n",
    "1. introduce an Gaussian blur\n",
    "\n",
    "We can combine the above augmentation techniques to generate 100s times of the training images, with just a few hundred real images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yyx0sL2ekZoi"
   },
   "outputs": [],
   "source": [
    "def my_imread(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "def zoom(image):\n",
    "    zoom = img_aug.Affine(scale=(1, 1.3))  # zoom from 100% (no zoom) to 130%\n",
    "    image = zoom.augment_image(image)\n",
    "    return image\n",
    "\n",
    "def pan(image):\n",
    "    # pan left / right / up / down about 10%\n",
    "    pan = img_aug.Affine(translate_percent= {\"x\" : (-0.1, 0.1), \"y\": (-0.1, 0.1)})\n",
    "    image = pan.augment_image(image)\n",
    "    return image\n",
    "\n",
    "def adjust_brightness(image):\n",
    "    # increase or decrease brightness by 30%\n",
    "    brightness = img_aug.Multiply((0.7, 1.3))\n",
    "    image = brightness.augment_image(image)\n",
    "    return image\n",
    "\n",
    "def blur(image):\n",
    "    kernel_size = random.randint(1, 5)  # kernel larger than 5 would make the image way too blurry\n",
    "    image = cv2.blur(image,(kernel_size, kernel_size))\n",
    "    return image\n",
    "\n",
    "def random_flip(image, steering_angle):\n",
    "    is_flip = random.randint(0, 1)\n",
    "    if is_flip == 1:\n",
    "        # randomly flip horizon\n",
    "        image = cv2.flip(image,1)\n",
    "        steering_angle = 180 - steering_angle\n",
    "    return image, steering_angle\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "image_orig = my_imread(image_paths[image_index])\n",
    "image_zoom = zoom(image_orig)\n",
    "axes[0].imshow(image_orig)\n",
    "axes[0].set_title(\"orig\")\n",
    "axes[1].imshow(image_zoom)\n",
    "axes[1].set_title(\"zoomed\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "image_orig = my_imread(image_paths[image_index])\n",
    "image_pan = pan(image_orig)\n",
    "axes[0].imshow(image_orig)\n",
    "axes[0].set_title(\"orig\")\n",
    "axes[1].imshow(image_pan)\n",
    "axes[1].set_title(\"panned\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "image_orig = my_imread(image_paths[image_index])\n",
    "image_flip, steering_angle = random_flip(image_orig, steering_angles[image_index])\n",
    "axes[0].imshow(image_orig)\n",
    "axes[0].set_title(\"orig\")\n",
    "axes[1].imshow(image_flip)\n",
    "axes[1].set_title(\"flipped, angle=%s\" % steering_angle)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "image_orig = my_imread(image_paths[image_index])\n",
    "image_brightness = adjust_brightness(image_orig)\n",
    "axes[0].imshow(image_orig)\n",
    "axes[0].set_title(\"orig\")\n",
    "axes[1].imshow(image_brightness)\n",
    "axes[1].set_title(\"brightness adjusted\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "image_orig = my_imread(image_paths[image_index])\n",
    "image_blur = blur(image_orig)\n",
    "axes[0].imshow(image_orig)\n",
    "axes[0].set_title(\"orig\")\n",
    "axes[1].imshow(image_blur)\n",
    "axes[1].set_title(\"blurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdQIzXiuo5zD"
   },
   "outputs": [],
   "source": [
    "# put it together\n",
    "def random_augment(image, steering_angle):\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = pan(image)\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = zoom(image)\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = blur(image)\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = adjust_brightness(image)\n",
    "    image, steering_angle = random_flip(image, steering_angle)\n",
    "    \n",
    "    return image, steering_angle\n",
    "\n",
    "# show a few randomly augmented images\n",
    "ncol = 2\n",
    "nrow = 10\n",
    "fig, axes = plt.subplots(nrow, ncol, figsize=(15, 50))\n",
    "\n",
    "for i in range(nrow):\n",
    "    rand_index = random.randint(0, len(image_paths) - 1)\n",
    "    image_path = image_paths[rand_index]\n",
    "    steering_angle_orig = steering_angles[rand_index]\n",
    "    \n",
    "    image_orig = my_imread(image_path)\n",
    "    image_aug, steering_angle_aug = random_augment(image_orig, steering_angle_orig)\n",
    "    \n",
    "    axes[i][0].imshow(image_orig)\n",
    "    axes[i][0].set_title(\"original, angle=%s\" % steering_angle_orig)\n",
    "    axes[i][1].imshow(image_aug)\n",
    "    axes[i][1].set_title(\"augmented, angle=%s\" % steering_angle_aug)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xCtiEgo0C4S"
   },
   "source": [
    "## Preprocess Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45-dWwTw0K5x"
   },
   "outputs": [],
   "source": [
    "def img_preprocess(image):\n",
    "    height, _, _ = image.shape\n",
    "    image = image[int(height/2):,:,:]  # remove top half of the image, as it is not relavant for lane following\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)  # Nvidia model said it is best to use YUV color space\n",
    "    image = cv2.GaussianBlur(image, (3,3), 0)\n",
    "    image = cv2.resize(image, (200,66)) # input image size (200,66) Nvidia model\n",
    "    image = image / 255 # normalizing, the processed image becomes black for some reason.  do we need this?\n",
    "    return image\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "image_orig = my_imread(image_paths[image_index])\n",
    "image_processed = img_preprocess(image_orig)\n",
    "axes[0].imshow(image_orig)\n",
    "axes[0].set_title(\"orig\")\n",
    "axes[1].imshow(image_processed)\n",
    "axes[1].set_title(\"processed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "envGeErj0LfP"
   },
   "source": [
    "## Create and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LB8_GDbn0VX4"
   },
   "outputs": [],
   "source": [
    "def simple_model():\n",
    "    model = Sequential(name='Simple_Model')\n",
    "    \n",
    "    # skipping 1st hiddel layer (nomralization layer), as we have normalized the data\n",
    "    \n",
    "    # Convolution Layers\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(66, 200, 3)))\n",
    "    model.add(MaxPool2D())\n",
    "\n",
    "    model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D())\n",
    "\n",
    "    model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    \n",
    "    # output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n",
    "    model.add(Dense(1)) \n",
    "    \n",
    "    # since this is a regression problem not classification problem,\n",
    "    # we use MSE (Mean Squared Error) as loss function\n",
    "    optimizer = Adam(lr=1e-3) # lr is learning rate\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-FjHgMhA2vl"
   },
   "outputs": [],
   "source": [
    "model = simple_model()\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQwQSh5fzEwy"
   },
   "outputs": [],
   "source": [
    "def image_data_generator(image_paths, steering_angles, batch_size, is_training):\n",
    "    while True:\n",
    "        batch_images = []\n",
    "        batch_steering_angles = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            random_index = random.randint(0, len(image_paths) - 1)\n",
    "            image_path = image_paths[random_index]\n",
    "            image = my_imread(image_paths[random_index])\n",
    "            steering_angle = steering_angles[random_index]\n",
    "            if is_training:\n",
    "                # training: augment image\n",
    "                image, steering_angle = random_augment(image, steering_angle)\n",
    "              \n",
    "            image = img_preprocess(image)\n",
    "            batch_images.append(image)\n",
    "            batch_steering_angles.append(steering_angle)\n",
    "            \n",
    "        yield( np.asarray(batch_images), np.asarray(batch_steering_angles))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7rvVKC_M1kUu"
   },
   "outputs": [],
   "source": [
    "ncol = 2\n",
    "nrow = 2\n",
    "\n",
    "X_train_batch, y_train_batch = next(image_data_generator(X_train, y_train, nrow, True))\n",
    "X_valid_batch, y_valid_batch = next(image_data_generator(X_valid, y_valid, nrow, False))\n",
    "\n",
    "fig, axes = plt.subplots(nrow, ncol, figsize=(15, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(nrow):\n",
    "    axes[i][0].imshow(X_train_batch[i])\n",
    "    axes[i][0].set_title(\"training, angle=%s\" % y_train_batch[i])\n",
    "    axes[i][1].imshow(X_valid_batch[i])\n",
    "    axes[i][1].set_title(\"validation, angle=%s\" % y_valid_batch[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sf3x_HDiM0ei"
   },
   "outputs": [],
   "source": [
    "# start Tensorboard before model fit, so we can see the epoch tick in Tensorboard\n",
    "# Jupyter Notebook embedded Tensorboard is a new feature in TF 2.0!!  \n",
    "\n",
    "# clean up log folder for tensorboard\n",
    "log_dir_root = f'{model_output_dir}/logs/'\n",
    "#!rm -rf $log_dir_root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knb7Cx1ze_t0"
   },
   "outputs": [],
   "source": [
    "# this block prevents the training from starting if we Run All\n",
    "DO_NOT_RUN_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cLqWYTGA3PG"
   },
   "outputs": [],
   "source": [
    "# saves the model weights after each epoch if the validation loss decreased\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=os.path.join(model_output_dir,'lane_navigation_check.h5'), verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "history = model.fit_generator(image_data_generator( X_train, y_train, batch_size=100, is_training=True),\n",
    "                              steps_per_epoch=300,\n",
    "                              epochs=10,\n",
    "                              validation_data = image_data_generator( X_valid, y_valid, batch_size=100, is_training=False),\n",
    "                              validation_steps=200,\n",
    "                              verbose=1,\n",
    "                              shuffle=1,\n",
    "                              callbacks=[checkpoint_callback])\n",
    "# always save model output as soon as model finishes training\n",
    "model.save(os.path.join(model_output_dir,'lane_navigation_CNN.h5'))\n",
    "\n",
    "date_str = datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "history_path = os.path.join(model_output_dir,'history.pickle')\n",
    "with open(history_path, 'wb') as f:\n",
    "    pickle.dump(history.history, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MB5VJmU0Vqu"
   },
   "source": [
    "## Check Trained Model on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUNqiczguJx4"
   },
   "outputs": [],
   "source": [
    "history.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pklx05KKQttt"
   },
   "outputs": [],
   "source": [
    "def test_data_generator(image_paths, steering_angles, batch_size, is_training):\n",
    "    while True:\n",
    "        batch_images = []\n",
    "        batch_steering_angles = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            index = i\n",
    "            image_path = image_paths[index]\n",
    "            image = my_imread(image_paths[index])\n",
    "            steering_angle = steering_angles[index]\n",
    "            if is_training:\n",
    "                # training: augment image\n",
    "                image, steering_angle = image, steering_angle\n",
    "              \n",
    "            image = img_preprocess(image)\n",
    "            batch_images.append(image)\n",
    "            batch_steering_angles.append(steering_angle)\n",
    "            \n",
    "        yield( np.asarray(batch_images), np.asarray(batch_steering_angles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cf8ls0EodC4v"
   },
   "outputs": [],
   "source": [
    "# plot training and validation losses\n",
    "# this should be the same as tensorboard\n",
    "history_path = os.path.join(model_output_dir,'history.pickle')\n",
    "with open(history_path, 'rb') as f:\n",
    "    history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KH_xNvr_A3ak"
   },
   "outputs": [],
   "source": [
    "history\n",
    "plt.plot(history['loss'],color='blue')\n",
    "plt.plot(history['val_loss'],color='red')\n",
    "plt.legend([\"training loss\", \"validation loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7IrK0KPf8uk"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def summarize_prediction(Y_true, Y_pred):\n",
    "    \n",
    "    mse = mean_squared_error(Y_true, Y_pred)\n",
    "    r_squared = r2_score(Y_true, Y_pred)\n",
    "    \n",
    "    print(f'mse       = {mse:.2}')\n",
    "    print(f'r_squared = {r_squared:.2%}')\n",
    "    print()\n",
    "    \n",
    "def predict_and_summarize(X, Y):\n",
    "    model_dir = '/content/gdrive/MyDrive/training_data/lane_navigation_CNN.h5'\n",
    "    model = load_model(model_dir)\n",
    "    Y_pred = model.predict(X)\n",
    "    summarize_prediction(Y, Y_pred)\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g238xj_XhymB"
   },
   "outputs": [],
   "source": [
    "n_tests = 100\n",
    "\n",
    "X_test, y_test = next(test_data_generator(X_valid, y_valid, 100, False))\n",
    "\n",
    "y_pred = predict_and_summarize(X_test, y_test)\n",
    "\n",
    "n_tests_show = 4\n",
    "fig, axes = plt.subplots(n_tests_show, 1, figsize=(10, 4 * n_tests_show))\n",
    "for i in range(n_tests_show):\n",
    "    axes[i].imshow(X_test[i])\n",
    "    axes[i].set_title(f\"actual angle={y_test[i]}, predicted angle={int(y_pred[i])}, diff = {int(y_pred[i])-y_test[i]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-09XwaJyvG7"
   },
   "source": [
    "## References\n",
    "1. Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat Flepp, Prasoon Goyal, Lawrence D. Jackel, Mathew Monfort, Urs Muller, Jiakai Zhang, Xin Zhang, Jake Zhao, Karol Zieba (2016) *End to End Learning for Self-Driving Cars*. Nvidia \n",
    "1. Rayan Slim, Amer Sharaf, Jad Slim (2017) *The Complete Self-Driving Car Course*. Udemy\n",
    "1. Keras Documentation (2019) https://github.com/keras-team/keras/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "end_to_end_lane_navigation_V4_simple_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
