{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OrScureymFU"
      },
      "source": [
        "# End-to-End Lane Navigation\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7g38ulzZCAbR"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj3E4BR6kNkZ"
      },
      "source": [
        "###RUN THIS CELL TO CONNECT TO GOOGLE DRIVE, CHECK THAT YOUR TRAINING DATA PATH IS CORRECT \n",
        "(NO NESTED TRAINING DATA FOLDERS) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rihBIMTlM7rm"
      },
      "outputs": [],
      "source": [
        "# Mount my Google Drive.  It will ask for an authenticate code\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "model_output_dir = '/content/gdrive/My Drive/training_data'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFZEdyZPtdMG"
      },
      "source": [
        "## Imports Packages and Loads Training Data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-BJrGUh00Cp",
        "outputId": "d31c849a-06dc-491d-8719-f9d2ac64767c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\tsample_data\n",
            "image_path: /content/gdrive/My Drive/training_data/video2.avi_112_095.png\n",
            "steering_Angle: 95\n",
            "Training data: 1038\n",
            "Validation data: 260\n"
          ]
        }
      ],
      "source": [
        "# python standard libraries\n",
        "import os\n",
        "import random\n",
        "import fnmatch\n",
        "import datetime\n",
        "import pickle\n",
        "\n",
        "# data processing\n",
        "import numpy as np\n",
        "np.set_printoptions(formatter={'float_kind':lambda x: \"%.4f\" % x})\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.width', 300)\n",
        "pd.set_option('display.float_format', '{:,.4f}'.format)\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "# tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential  \n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "# sklearn\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# imaging\n",
        "import cv2\n",
        "from imgaug import augmenters as img_aug\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "from PIL import Image\n",
        "\n",
        "# import images\n",
        "!cd /content\n",
        "\n",
        "!ls\n",
        "data_dir = '/content/gdrive/My Drive/training_data'\n",
        "file_list = os.listdir(data_dir)\n",
        "image_paths = []\n",
        "steering_angles = []\n",
        "pattern = \"*.png\"\n",
        "for filename in file_list:\n",
        "    if fnmatch.fnmatch(filename, pattern):\n",
        "        image_paths.append(os.path.join(data_dir,filename))\n",
        "        angle = int(filename[-7:-4])  # 092 part of video01_143_092.png is the angle. 90 is go straight\n",
        "        steering_angles.append(angle)\n",
        "\n",
        "image_index = 20\n",
        "\n",
        "print(\"image_path: %s\" % image_paths[image_index] )\n",
        "print(\"steering_Angle: %d\" % steering_angles[image_index] )\n",
        "df = pd.DataFrame()\n",
        "df['ImagePath'] = image_paths\n",
        "df['Angle'] = steering_angles\n",
        "\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split( image_paths, steering_angles, test_size=0.2)\n",
        "print(\"Training data: %d\\nValidation data: %d\" % (len(X_train), len(X_valid)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaZEfJxdi796"
      },
      "source": [
        "##Image Augumentation\n",
        "Since we only have a few hundred images, to train a deep network, we need a lot more images.   Instead of running our car, let's try to augment our data. There are a couple of ways to do that.\n",
        "\n",
        "1. Zoom: crop out a smaller image from the center\n",
        "1. Pan: crop out a smaller image from left or right side\n",
        "1. adjust brightness of the image\n",
        "1. flip the image horizontally, i.e do a left to right flip, and change the steering angle coorespondingly\n",
        "1. introduce an Gaussian blur\n",
        "\n",
        "We can combine the above augmentation techniques to generate 100s times of the training images, with just a few hundred real images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Yyx0sL2ekZoi"
      },
      "outputs": [],
      "source": [
        "def my_imread(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    return image\n",
        "\n",
        "def zoom(image):\n",
        "    zoom = img_aug.Affine(scale=(1, 1.3))  # zoom from 100% (no zoom) to 130%\n",
        "    image = zoom.augment_image(image)\n",
        "    return image\n",
        "\n",
        "def pan(image):\n",
        "    # pan left / right / up / down about 10%\n",
        "    pan = img_aug.Affine(translate_percent= {\"x\" : (-0.1, 0.1), \"y\": (-0.1, 0.1)})\n",
        "    image = pan.augment_image(image)\n",
        "    return image\n",
        "\n",
        "def adjust_brightness(image):\n",
        "    # increase or decrease brightness by 30%\n",
        "    brightness = img_aug.Multiply((0.7, 1.3))\n",
        "    image = brightness.augment_image(image)\n",
        "    return image\n",
        "\n",
        "def blur(image):\n",
        "    kernel_size = random.randint(1, 5)  # kernel larger than 5 would make the image way too blurry\n",
        "    image = cv2.blur(image,(kernel_size, kernel_size))\n",
        "    return image\n",
        "\n",
        "def random_flip(image, steering_angle):\n",
        "    is_flip = random.randint(0, 1)\n",
        "    if is_flip == 1:\n",
        "        # randomly flip horizon\n",
        "        image = cv2.flip(image,1)\n",
        "        steering_angle = 180 - steering_angle\n",
        "    return image, steering_angle\n",
        "\n",
        "# put it together\n",
        "def random_augment(image, steering_angle):\n",
        "    if np.random.rand() < 0.5:\n",
        "        image = pan(image)\n",
        "    if np.random.rand() < 0.5:\n",
        "        image = zoom(image)\n",
        "    if np.random.rand() < 0.5:\n",
        "        image = blur(image)\n",
        "    if np.random.rand() < 0.5:\n",
        "        image = adjust_brightness(image)\n",
        "    image, steering_angle = random_flip(image, steering_angle)\n",
        "    \n",
        "    return image, steering_angle\n",
        "\n",
        "ncol = 2\n",
        "nrow = 10\n",
        "\n",
        "\n",
        "for i in range(nrow):\n",
        "    rand_index = random.randint(0, len(image_paths) - 1)\n",
        "    image_path = image_paths[rand_index]\n",
        "    steering_angle_orig = steering_angles[rand_index]\n",
        "    \n",
        "    image_orig = my_imread(image_path)\n",
        "    image_aug, steering_angle_aug = random_augment(image_orig, steering_angle_orig)\n",
        "\n",
        "\n",
        "def img_preprocess(image):\n",
        "    height, _, _ = image.shape\n",
        "    image = image[int(height/2):,:,:]  # remove top half of the image, as it is not relavant for lane following\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)  # Nvidia model said it is best to use YUV color space\n",
        "    image = cv2.GaussianBlur(image, (3,3), 0)\n",
        "    image = cv2.resize(image, (200,66)) # input image size (200,66) Nvidia model\n",
        "    image = image / 255 # normalizing, the processed image becomes black for some reason.  do we need this?\n",
        "    return image\n",
        "\n",
        "\n",
        "\n",
        "def img_preprocess(image):\n",
        "    height, _, _ = image.shape\n",
        "    image = image[int(height/2):,:,:]  # remove top half of the image, as it is not relavant for lane following\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)  # Nvidia model said it is best to use YUV color space\n",
        "    image = cv2.GaussianBlur(image, (3,3), 0)\n",
        "    image = cv2.resize(image, (200,66)) # input image size (200,66) Nvidia model\n",
        "    image = image / 255 # normalizing, the processed image becomes black for some reason.  do we need this?\n",
        "    return image\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "envGeErj0LfP"
      },
      "source": [
        "## RUN THIS CELL TO DEFINE YOUR MODEL \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB8_GDbn0VX4"
      },
      "outputs": [],
      "source": [
        "def nvidia_model():\n",
        "    model = Sequential(name='Nvidia_Model')\n",
        "\n",
        "    \n",
        "\n",
        "####################### WRITE YOUR MODEL STARTING HERE (THIS IS A VERY SIMPLE EXAMPLE NETWORK ) #########################\n",
        "\n",
        "    #FIRST CONVOLUTIONAL LAYER IN ANY NETWORK YOU DESIGN MUST HAVE input_shape=(66, 200, 3) ARGUMENT \n",
        "\n",
        "    # CONVOLUTIONAL LAYERS HERE \n",
        "    model.add(Conv2D(16,3, activation=\"relu\", input_shape=(66, 200, 3)))\n",
        "    model.add(MaxPool2D()) \n",
        "\n",
        "    model.add(Conv2D(32, 3, activation=\"relu\"))\n",
        "    model.add(MaxPool2D()) \n",
        "    \n",
        "    #THIS LAYER FLATTENS CONVOLUTIONAL LAYERS INTO A COLUMN VECTOR (DONT CHANGE THIS LAYER) \n",
        "    model.add(Flatten())\n",
        "\n",
        "    # FULLY CONNECTED (DENSE) LAYERS HERE\n",
        "\n",
        "    \n",
        "\n",
        "#########################################################################################################################\n",
        "\n",
        "\n",
        "    # output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n",
        "    model.add(Dense(1)) \n",
        "    \n",
        "    # since this is a regression problem not classification problem,\n",
        "    # we use MSE (Mean Squared Error) as loss function\n",
        "    optimizer = Adam(lr=1e-3) # lr is learning rate\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "model = nvidia_model()\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "\n",
        "def image_data_generator(image_paths, steering_angles, batch_size, is_training):\n",
        "    while True:\n",
        "        batch_images = []\n",
        "        batch_steering_angles = []\n",
        "        \n",
        "        for i in range(batch_size):\n",
        "            random_index = random.randint(0, len(image_paths) - 1)\n",
        "            image_path = image_paths[random_index]\n",
        "            image = my_imread(image_paths[random_index])\n",
        "            steering_angle = steering_angles[random_index]\n",
        "            if is_training:\n",
        "                # training: augment image\n",
        "                image, steering_angle = random_augment(image, steering_angle)\n",
        "              \n",
        "            image = img_preprocess(image)\n",
        "            batch_images.append(image)\n",
        "            batch_steering_angles.append(steering_angle)\n",
        "            \n",
        "        yield( np.asarray(batch_images), np.asarray(batch_steering_angles))\n",
        "\n",
        "\n",
        "ncol = 2\n",
        "nrow = 2\n",
        "\n",
        "X_train_batch, y_train_batch = next(image_data_generator(X_train, y_train, nrow, True))\n",
        "X_valid_batch, y_valid_batch = next(image_data_generator(X_valid, y_valid, nrow, False))\n",
        "\n",
        "\n",
        "# start Tensorboard before model fit, so we can see the epoch tick in Tensorboard\n",
        "\n",
        "# clean up log folder for tensorboard\n",
        "log_dir_root = f'{model_output_dir}/logs/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9dQsOARWkRe"
      },
      "source": [
        "## RUN THIS CELL TO TRAIN YOUR MODEL \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cLqWYTGA3PG"
      },
      "outputs": [],
      "source": [
        "# saves the model weights after each epoch if the validation loss decreased\n",
        "checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=os.path.join(model_output_dir,'lane_navigation_check.h5'), verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "history = model.fit_generator(image_data_generator( X_train, y_train, batch_size= 36, is_training=True),\n",
        "                              steps_per_epoch=300,\n",
        "                              epochs=10,\n",
        "                              validation_data = image_data_generator( X_valid, y_valid, batch_size=1, is_training=False),\n",
        "                              validation_steps=200,\n",
        "                              verbose=1,\n",
        "                              shuffle=1,\n",
        "                              callbacks=[checkpoint_callback])\n",
        "# always save model output as soon as model finishes training\n",
        "model.save(os.path.join(model_output_dir,'lane_navigation_final.h5'))\n",
        "\n",
        "date_str = datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
        "history_path = os.path.join(model_output_dir,'history.pickle')\n",
        "with open(history_path, 'wb') as f:\n",
        "    pickle.dump(history.history, f, pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Lane_navigation_V8_simple_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}